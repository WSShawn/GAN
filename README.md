# Generative Adversarial Networks

## Introduction and concept

Generative Adversarial Networks (GANs) represent a class of Deep Learning Frameworks which have firstly been introduced by Ian Goodfellow in 2014. While their spectrum of application is becoming larger with research, the main focus of GANs has been image processing.

The main idea behind GANs consists in the competition between 2 neural networks in a zero-sum game, the scope of each network being to improve its prediction accuracy. One network is named the "Generator" and the other the "Discriminator". The Generator's goal is to create fake data, with the ultimate goal of its output to be perceived as real. The goal of the Discrimnator is to look at the data generated by the Generator and label the data as "real" or "fake". As the data that the application of Generative Adversarial Networks is mainly focused on, as well as the data in our study is represented by images, we will focus on implementing Deep Convolutional Generative Adversarial Networks (DCGANs).

## Data 

The dataset used in our study is the Celeba Dataset. It represents a collection of more than 200K photos of celebrities, which come in .jpg format.



## Deep Convolutional Generative Adversarial networks 

From a general point of view, Convolutional Neural Networks represent a particular type of neural networks that posess an ability to detect patterns in the data (for example, shapes, corners or edges in the case of images). Their hidden layers, called "Convolutional Layers", receive input, transform it and then pass it to the following layers. The operation that corresponds to the transformation is called a "Convolution".

### Convolution

The object at the basis of the convolution process is the kernel. Given the 3-dimensional characterisation of our data (height, width and values of the RGB channel), the kernel can be initialized as 3-dimensional, with the 3rd dimension representing the number of filters applied, or 2-dimensional, meaning that the same filter will be applied to each of the 3 color channels. The values that constitute the kernel are randomly initialized and will be further optimized according to the accuracy and loss of the convolution process.

The kernel is then passed along the image, row by row and column by column, until it has slid over all the pixels of the image. A dot product is applied between the kernel and the surface on the image on which it slides. The resulting image is the output matrix. In the case of a Convolutional Neural Network, the output obtained by the convolution inside a hidden layer is passed as input to the next hidden layer.

![convolution1](https://user-images.githubusercontent.com/114659655/200131876-4e9d595c-9ff9-4f57-9c58-b13382168a12.png)


